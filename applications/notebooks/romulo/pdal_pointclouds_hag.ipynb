{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PointClouds in Spark using PDAL\n",
    "We calculate the Normalized Height for each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geotrellis.pointcloud.spark.Extent3D\n",
    "import geotrellis.pointcloud.spark.io.hadoop.HadoopPointCloudRDD\n",
    "import io.pdal.Pipeline\n",
    "import io.pdal.pipeline.{FerryFilter, HagFilter, LasRead, LasWrite}\n",
    "import geotrellis.spark.io.hadoop.HadoopCollectionLayerReader\n",
    "import org.apache.hadoop.fs.Path\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark.rdd.RDD\n",
    "import spire.syntax.cfor._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sparkContext = org.apache.spark.SparkContext@202e8b84\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://145.100.58.104:4040)\" target=\"new_tab\">Spark UI: app-20180418094748-0000</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark app-20180418094748-0000: Some(http://145.100.58.104:4040)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit val sparkContext = sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tiles_path = /data/local/home/ecolidar/\n",
       "tile = C_25EZ2\n",
       "laz_filepath = /data/local/home/ecolidar/C_25EZ2.laz\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/data/local/home/ecolidar/C_25EZ2.laz"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tiles_path = \"/data/local/home/ecolidar/\"\n",
    "val tile = \"C_25EZ2\"\n",
    "val laz_filepath = tiles_path + tile + \".laz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read local and save the result back to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "las_pipelineExpr = List(LasRead(/data/local/home/ecolidar/C_25EZ2.las,None,None,None,None,None,readers.las), HagFilter(filters.hag), FerryFilter(Z=HeightAboveGround,filters.ferry), LasWrite(/data/local/home/ecolidar/C_25EZ2_hag.laz,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,writers.las))\n",
       "las_pipeline = io.pdal.Pipeline@4ac1c789\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "io.pdal.Pipeline@4ac1c789"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val las_pipelineExpr = LasRead(las_filepath) ~ HagFilter() ~ FerryFilter(dimensions = \"Z=HeightAboveGround\") ~ LasWrite(tiles_path + tile + \"_hag.laz\")\n",
    "val las_pipeline: Pipeline = las_pipelineExpr.toPipeline\n",
    "las_pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify if the saved file has HeightAboveGround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read HDFS and apply HagFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "las_path = /user/hadoop/ahn3/C_25EZ2.las\n",
       "laz_path = /user/hadoop/ahn3/C_25EZ2.laz\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/user/hadoop/ahn3/C_25EZ2.laz"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val laz_path = new Path(\"/user/hadoop/ahn3/C_25EZ2.laz\")\n",
    "val pipelineExpr = Read(\"local\") ~ HagFilter() ~ FerryFilter(dimensions = \"HeightAboveGround=Z\")\n",
    "val rdd_laz = HadoopPointCloudRDD(laz_path, options = HadoopPointCloudRDD.Options(pipeline = pipelineExpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify if HeightAboveGround shows up in the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(\"{\n",
       "  \"schema\":\n",
       "  {\n",
       "    \"dimensions\":\n",
       "    [\n",
       "      {\n",
       "        \"name\": \"X\",\n",
       "        \"size\": 8,\n",
       "        \"type\": \"floating\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Y\",\n",
       "        \"size\": 8,\n",
       "        \"type\": \"floating\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Z\",\n",
       "        \"size\": 8,\n",
       "        \"type\": \"floating\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Intensity\",\n",
       "        \"size\": 2,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"ReturnNumber\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"NumberOfReturns\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"ScanDirectionFlag\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"EdgeOfFlightLine\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigne...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{\n",
       "  \"schema\":\n",
       "  {\n",
       "    \"dimensions\":\n",
       "    [\n",
       "      {\n",
       "        \"name\": \"X\",\n",
       "        \"size\": 8,\n",
       "        \"type\": \"floating\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Y\",\n",
       "        \"size\": 8,\n",
       "        \"type\": \"floating\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Z\",\n",
       "        \"size\": 8,\n",
       "        \"type\": \"floating\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Intensity\",\n",
       "        \"size\": 2,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"ReturnNumber\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"NumberOfReturns\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"ScanDirectionFlag\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"EdgeOfFlightLine\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Classification\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"ScanAngleRank\",\n",
       "        \"size\": 4,\n",
       "        \"type\": \"floating\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"UserData\",\n",
       "        \"size\": 1,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"PointSourceId\",\n",
       "        \"size\": 2,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"GpsTime\",\n",
       "        \"size\": 8,\n",
       "        \"type\": \"floating\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Red\",\n",
       "        \"size\": 2,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Green\",\n",
       "        \"size\": 2,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"Blue\",\n",
       "        \"size\": 2,\n",
       "        \"type\": \"unsigned\"\n",
       "      },\n",
       "      {\n",
       "        \"name\": \"HeightAboveGround\",\n",
       "        \"size\": 8,\n",
       "        \"type\": \"floating\"\n",
       "      }\n",
       "    ]\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_laz.map{ case (h, i) => h.schema}.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the points into RDD and compare Z with NormalizedHeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val points :RDD[(Double, Double, Double, Byte, Float)] = rdd_laz.flatMap(_._2).mapPartitions{ _.map { packedPoints =>\n",
    "\n",
    "  var res = new Array[(Double, Double, Double, Byte, Float)](packedPoints.length)\n",
    "  cfor(0)(_ < packedPoints.length, _ + 1) { i =>\n",
    "    res(i) = (packedPoints.getX(i), packedPoints.getY(i), packedPoints.getZ(i), packedPoints.getByte(i, dim = \"Classification\"), packedPoints.getFloat(i, dim = \"HeightAboveGround\"))\n",
    "  }\n",
    "  res\n",
    "}}.flatMap( m => m).filter(_._4 != 2).filter(_._3 > 0)\n",
    "points2.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify if the created file and uploaded to HDFS has Normalized Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "laz_path = /user/hadoop/ahn3/C_25EZ2_hag.laz\n",
       "rdd_laz = NewHadoopRDD[152] at newAPIHadoopRDD at HadoopPointCloudRDD.scala:76\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val laz_path = new Path(\"/user/hadoop/ahn3/C_25EZ2_hag.laz\")\n",
    "val rdd_laz = HadoopPointCloudRDD(laz_path)\n",
    "rdd_laz.cache()\n",
    "rdd_laz.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "points = MapPartitionsRDD[157] at filter at <console>:100\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[157] at filter at <console>:100"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val points :RDD[(Double, Double, Double, Byte)] = rdd_laz.flatMap(_._2).mapPartitions{ _.map { packedPoints =>\n",
    "  var res = new Array[(Double, Double, Double, Byte)](packedPoints.length)\n",
    "  cfor(0)(_ < packedPoints.length, _ + 1) { i =>\n",
    "    res(i) = (packedPoints.getX(i), packedPoints.getY(i), packedPoints.getZ(i), packedPoints.getByte(i, dim = \"Classification\"))\n",
    "  }\n",
    "  res\n",
    "}}.flatMap( m => m).filter(_._4 != 2).filter(_._3 > 0)\n",
    "val points10 = points.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
