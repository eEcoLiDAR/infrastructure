{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrames and Magellan\n",
    "\n",
    "We advise the read of the [sql programming guide/sql](https://spark.apache.org/docs/2.1.1/sql-programming-guide.html#sql) and visit [Magellan repository](https://github.com/harsha2010/magellan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg.Vector\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.types.{DoubleType, StructField, StructType}\n",
    "import org.apache.spark.sql.{Row, SparkSession}\n",
    "import org.apache.spark.{SparkConf, SparkContext}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sqlContext = org.apache.spark.sql.SQLContext@4ae17bc0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SQLContext@4ae17bc0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "import sqlContext.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dir_path = hdfs:///user/emma/ecolidar/\n",
       "offline_dir_path = hdfs:///user/emma/ecolidar/\n",
       "las_cell = C_25EZ2\n",
       "parquet_file = C_25EZ2.parquet\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "C_25EZ2.parquet"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var dir_path = \"hdfs:///user/emma/ecolidar/\"\n",
    "var offline_dir_path = \"hdfs:///user/emma/ecolidar/\"\n",
    "var las_cell = \"C_25EZ2\"\n",
    "var parquet_file = las_cell + \".parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrame\n",
    "\n",
    "The dataframe is loaded from a Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [intensity: smallint, raw_classification: tinyint ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[intensity: smallint, raw_classification: tinyint ... 3 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = sqlContext.read.parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><td>308</td><td>2</td><td>125360792</td><td>488733112</td><td>423</td></tr>\n",
       "<tr><td>45</td><td>1</td><td>125358802</td><td>488732300</td><td>4814</td></tr>\n",
       "<tr><td>357</td><td>2</td><td>125361146</td><td>488733277</td><td>446</td></tr>\n",
       "<tr><td>40</td><td>1</td><td>125358863</td><td>488732341</td><td>5336</td></tr>\n",
       "<tr><td>421</td><td>2</td><td>125361495</td><td>488733437</td><td>439</td></tr>\n",
       "<tr><td>443</td><td>2</td><td>125361860</td><td>488733607</td><td>423</td></tr>\n",
       "<tr><td>12</td><td>1</td><td>125359004</td><td>488732432</td><td>6407</td></tr>\n",
       "<tr><td>357</td><td>2</td><td>125362169</td><td>488733752</td><td>538</td></tr>\n",
       "<tr><td>383</td><td>2</td><td>125362538</td><td>488733923</td><td>525</td></tr>\n",
       "<tr><td>356</td><td>1</td><td>125362867</td><td>488734078</td><td>622</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----+-----+-----------+-----------+------+\n",
       "| 308 | 2   | 125360792 | 488733112 | 423  |\n",
       "| 45  | 1   | 125358802 | 488732300 | 4814 |\n",
       "| 357 | 2   | 125361146 | 488733277 | 446  |\n",
       "| 40  | 1   | 125358863 | 488732341 | 5336 |\n",
       "| 421 | 2   | 125361495 | 488733437 | 439  |\n",
       "| 443 | 2   | 125361860 | 488733607 | 423  |\n",
       "| 12  | 1   | 125359004 | 488732432 | 6407 |\n",
       "| 357 | 2   | 125362169 | 488733752 | 538  |\n",
       "| 383 | 2   | 125362538 | 488733923 | 525  |\n",
       "| 356 | 1   | 125362867 | 488734078 | 622  |\n",
       "+-----+-----+-----------+-----------+------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Temporary table or view\n",
    "\n",
    "It is possible to create a temporary table or view from a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(las_cell + \"_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show existent tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+\n",
      "|database|  tableName|isTemporary|\n",
      "+--------+-----------+-----------+\n",
      "|        |c_25ez2_tab|       true|\n",
      "+--------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a simple SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res = [intensity: smallint, raw_classification: tinyint ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[intensity: smallint, raw_classification: tinyint ... 3 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val res = sqlContext.sql(\"select * from \" + las_cell + \"_tab where intensity = 277 and z = -444 and x = 125377487 limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+---------+---------+----+                         \n",
      "|intensity|raw_classification|        x|        y|   z|\n",
      "+---------+------------------+---------+---------+----+\n",
      "|      277|                 9|125377487|487500057|-444|\n",
      "+---------+------------------+---------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magellan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import magellan.{Point, Polygon}\n",
    "import org.apache.spark.sql.magellan.dsl.expressions._\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 14:===============================================>        (17 + 2) / 20]+-----------------+\n",
      "|            point|\n",
      "+-----------------+\n",
      "|Point(-1.0, -1.0)|\n",
      "| Point(-1.0, 1.0)|\n",
      "| Point(1.0, -1.0)|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "points = [point: point]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[point: point]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Only 2D points are supported.\n",
    "val points = sc.parallelize(Seq((-1.0, -1.0), (-1.0, 1.0), (1.0, -1.0))).toDF(\"x\", \"y\").select(point($\"x\", $\"y\").as(\"point\"))\n",
    "\n",
    "points.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of points from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               point|\n",
      "+--------------------+\n",
      "|Point(1.25360792E...|\n",
      "|Point(1.25358802E...|\n",
      "|Point(1.25361146E...|\n",
      "|Point(1.25358863E...|\n",
      "|Point(1.25361495E...|\n",
      "|Point(1.2536186E8...|\n",
      "|Point(1.25359004E...|\n",
      "|Point(1.25362169E...|\n",
      "|Point(1.25362538E...|\n",
      "|Point(1.25362867E...|\n",
      "|Point(1.25363318E...|\n",
      "|Point(1.25363672E...|\n",
      "|Point(1.25363609E...|\n",
      "|Point(1.25364027E...|\n",
      "|Point(1.25363769E...|\n",
      "|Point(1.25364381E...|\n",
      "|Point(1.25364341E...|\n",
      "|Point(1.25364777E...|\n",
      "|Point(1.25364499E...|\n",
      "|Point(1.25365127E...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lidar_points = [point: point]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[point: point]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lidar_points = df.select(point($\"x\", $\"y\").as(\"point\"))\n",
    "\n",
    "lidar_points.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class PolygonRecord\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import magellan.{Point, Polygon}\n",
    "case class PolygonRecord(polygon: Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ring = Array(Point(1.0, 1.0), Point(1.0, -1.0), Point(-1.0, -1.0), Point(-1.0, 1.0), Point(1.0, 1.0))\n",
       "polygons = [polygon: polygon]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[polygon: polygon]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ring = Array(Point(1.0, 1.0), Point(1.0, -1.0), Point(-1.0, -1.0), Point(-1.0, 1.0), Point(1.0, 1.0))\n",
    "val polygons = sc.parallelize(Seq(PolygonRecord(Polygon(Array(0), ring)))).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+                                                                 \n",
      "|point|polygon|\n",
      "+-----+-------+\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lidar_points.join(polygons).where($\"point\" within $\"polygon\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+                                                                 \n",
      "|point|polygon|\n",
      "+-----+-------+\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lidar_points.join(polygons).where($\"point\" intersects $\"polygon\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+                                                                 \n",
      "|point|polygon|\n",
      "+-----+-------+\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lidar_points.join(polygons).where($\"point\" >? $\"polygon\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices and Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t0 = 0\n",
       "t1 = 0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//To enable spatial joins in Magellan, add a spatial join rule to Spark by injecting the following code before the join:\n",
    "var t0 : Long = 0\n",
    "var t1 : Long = 0\n",
    "magellan.Utils.injectRules(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:65: error: reassignment to val\n",
       "       polygons = polygons.index(30)\n",
       "                ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Furthermore, during the join, you will need to provide Magellan a hint of the precision at which to create indices for the join\n",
    "polygons = polygons.index(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within using a indexed Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 100:======================================================>(74 + 1) / 75]+-----+-------+\n",
      "|point|polygon|\n",
      "+-----+-------+\n",
      "+-----+-------+\n",
      "\n",
      "Elapsed time: 56119ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "t0 = 9300304969224\n",
       "t1 = 9356424393008\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9356424393008"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = System.nanoTime()\n",
    "lidar_points.join(polygons).where($\"point\" within $\"polygon\").show()\n",
    "t1 = System.nanoTime()\n",
    "println(\"Elapsed time: \" + ((t1 - t0) / 1000000) + \" ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 115:======================================================>(74 + 1) / 75]+-----+-------+\n",
      "|point|polygon|\n",
      "+-----+-------+\n",
      "+-----+-------+\n",
      "\n",
      "Elapsed time: 60003ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "t0 = 9361952487099\n",
       "t1 = 9421956415493\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9421956415493"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = System.nanoTime()\n",
    "lidar_points.join(polygons).where($\"point\" within $\"polygon\").show()\n",
    "t1 = System.nanoTime()\n",
    "println(\"Elapsed time: \" + ((t1 - t0) / 1000000) + \" ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
